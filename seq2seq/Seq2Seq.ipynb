{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate with seq2seq model \n",
    "You are going to build a calculator for evaluating arithmetic expressions, by taking a string as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "We do not need any data to be downloaded, we will generate it all by ourselves. We will use two operators addition and subtraction, working with positive integer numbers in some range. Here are some inputs and some ideal outputs proveived by our networks\n",
    "    \n",
    "    Input: '1+2'\n",
    "    Output: '3'\n",
    "    \n",
    "    Input: '0-99'\n",
    "    Output: '-99'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generate_equations function first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_equations(allowed_operator, dataset_size, min_value, max_value):\n",
    "    sample = []\n",
    "    for i in range(dataset_size):\n",
    "        l = random.randint(min_value, max_value)\n",
    "        r = random.randint(min_value, max_value)\n",
    "        op = random.choice(allowed_operator)\n",
    "        if op == \"-\":\n",
    "            sulotion = l - r\n",
    "        if op == '+':\n",
    "            sulotion = l + r \n",
    "        sample.append((str(l)+op+str(r), str(sulotion)))\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8991-9721', '-730'), ('8542+3274', '11816'), ('3972+1648', '5620')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "equations = generate_equations([\"+\", \"-\"], 3, 0, 9999)\n",
    "equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "allowed_operator = [\"+\", \"-\"]\n",
    "dataset_size = 100000\n",
    "data = generate_equations(allowed_operator, dataset_size, 0, 9999)\n",
    "train_set, test_set = train_test_split(data, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "('5250+7736', '12986')\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for network \n",
    "The next stage is to creating mappings of the characters to their indices in some vocabulary. The dictionary is fixed(0-9, +, -), so it is easy to encode the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#': 2, '3': 7, '2': 6, '+': 3, '4': 8, '^': 0, '0': 14, '8': 12, '5': 9, '-': 4, '9': 13, '1': 5, '$': 1, '7': 11, '6': 10}\n",
      "{0: '^', 1: '$', 2: '#', 3: '+', 4: '-', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '0'}\n"
     ]
    }
   ],
   "source": [
    "word2id = {word:idx for (idx, word) in enumerate(\"^$#+-1234567890\")}\n",
    "id2word = {idx:word for (idx, word) in enumerate(\"^$#+-1234567890\")}\n",
    "print(word2id)\n",
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special symbols\n",
    "start_symbol = '^'   #0, beginning of the decoding\n",
    "end_symbol = \"$\"     #1, end of the string, both for input and output\n",
    "padding_symbol = '#' #2, padding symbol, to make the input placeholds' length consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "Convert a sentence to a list of vocabulary word.\n",
    "* Predifined length padding_len\n",
    "* Padding with \"#\"\n",
    "* Ends with \"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_ids(sentence, word2id, padded_len):\n",
    "    sent_ids = [word2id[i] for i in sentence]\n",
    "    if (len(sent_ids) >= padded_len):\n",
    "        sent_ids = sent_ids[:padded_len]\n",
    "        sent_ids[-1] = 1\n",
    "    else:\n",
    "        sent_ids.append(1)\n",
    "        while(len(sent_ids) < padded_len):\n",
    "            sent_ids.append(2)\n",
    "    sent_len = min(len(sentence)+1, padded_len)\n",
    "    return sent_ids, sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([5, 6, 7, 3, 5, 6, 1], 7) \n",
      " ([5, 6, 7, 3, 5, 6, 7, 1], 8) \n",
      " ([5, 6, 7, 3, 5, 6, 7, 1, 2, 2], 8)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"123+123\"\n",
    "print(sentence_to_ids(sentence, word2id, 7),\"\\n\",\n",
    "      sentence_to_ids(sentence, word2id, 8),\"\\n\",\n",
    "      sentence_to_ids(sentence, word2id, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert back\n",
    "def ids_to_sentence(ids, id2word):\n",
    "    return [id2word[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '+', '1', '2', '$']\n",
      "['1', '2', '3', '+', '1', '2', '3', '$']\n",
      "['1', '2', '3', '+', '1', '2', '3', '$', '#', '#']\n"
     ]
    }
   ],
   "source": [
    "print(ids_to_sentence([5,6,7,3,5,6,1], id2word))\n",
    "print(ids_to_sentence([5, 6, 7, 3, 5, 6, 7, 1], id2word))\n",
    "print(ids_to_sentence([5, 6, 7, 3, 5, 6, 7, 1, 2, 2], id2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network building\n",
    "### Generate batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_ids(sentences, word2id, max_len):\n",
    "    max_len_in_batch = min(max(len(s) for s in sentences)+1, max_len)\n",
    "    batch_ids, batch_ids_len = [], []\n",
    "    for sentence in sentences:\n",
    "        ids, ids_len = sentence_to_ids(sentence, word2id, max_len_in_batch)\n",
    "        batch_ids.append(ids)\n",
    "        batch_ids_len.append(ids_len)\n",
    "    return batch_ids, batch_ids_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(samples, batch_size = 64):\n",
    "    X, Y = [], []\n",
    "    for i, (x,y) in enumerate(samples, 1):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        if i%batch_size == 0:\n",
    "            yield X, Y\n",
    "            X, Y = [], []\n",
    "    if X and Y:\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 6, 9, 14, 3, 11, 11, 7, 10, 1], [5, 6, 13, 12, 10, 1, 2, 2, 2, 2]] [10, 6]\n"
     ]
    }
   ],
   "source": [
    "sentences =  train_set[0]\n",
    "ids, sent_lens = batch_to_ids(sentences, word2id, max_len = 100)\n",
    "print(ids, sent_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_placeholders(self):\n",
    "    self.input_batch = tf.placeholder(shape = (None, None), dtype=tf.int32, name = \"input_batch\")\n",
    "    self.input_batch_lengths = tf.placeholder(shape = (None,), dtype=tf.int32, name = \"input_batch_lengths\")\n",
    "    \n",
    "    self.ground_truth = tf.placeholder(shape = (None, None), dtype=tf.int32)\n",
    "    self.ground_truth_lengths = tf.placeholder(shape = (None, ), dtype = tf.int32)\n",
    "    \n",
    "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape = [])\n",
    "    self.learning_rate_ph = tf.placeholder(dtype=tf.float32, shape = [])\n",
    "Seq2SeqModel.__declare_placeholders = classmethod(declare_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the layer(Embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform as a dictionary to encode the input batch()\n",
    "def create_embeddings(self, vocab_size, embeddings_size):\n",
    "    random_initializer = tf.random_uniform((vocab_size, embeddings_size), -1.0, 1.0)\n",
    "    self.embeddings = tf.Variable(random_initializer)\n",
    "    \n",
    "    self.input_batch_embedded = tf.nn.embedding_lookup(self.embeddings, self.input_batch)\n",
    "Seq2SeqModel.__create_embeddings = classmethod(create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Encoding an input sequence to a real-valued vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(self, hidden_size):\n",
    "    encoder_cell = tf.nn.run_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(hidden_size),\n",
    "                                                input_keep_prob = self.dropout_ph,\n",
    "                                                output_keep_prob = self.dropout_ph)\n",
    "    \n",
    "    _, self.final_encoder_state = tf.nn.dynamic_rnn(encoder_cell, \n",
    "                                                   self.input_batch_embedded,\n",
    "                                                   dtype = tf.float32,\n",
    "                                                   sequence_length = self.input_batch_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.__build_encoder = classmethod(build_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a3b3c3a2b'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'aaabbbcccaab'\n",
    "a += ' '\n",
    "current = a[0]\n",
    "count = 1\n",
    "s = ''\n",
    "for i in a[1:]:\n",
    "    if i == current:\n",
    "        count += 1\n",
    "    else:\n",
    "        if count == 1:\n",
    "            s += current\n",
    "        else:\n",
    "            s = s + current + str(count)\n",
    "        current = i\n",
    "        count = 1\n",
    "print(s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
