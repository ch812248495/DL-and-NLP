{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate with seq2seq model \n",
    "You are going to build a calculator for evaluating arithmetic expressions, by taking a string as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "We do not need any data to be downloaded, we will generate it all by ourselves. We will use two operators addition and subtraction, working with positive integer numbers in some range. Here are some inputs and some ideal outputs proveived by our networks\n",
    "    \n",
    "    Input: '1+2'\n",
    "    Output: '3'\n",
    "    \n",
    "    Input: '0-99'\n",
    "    Output: '-99'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generate_equations function first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_equations(allowed_operator, dataset_size, min_value, max_value):\n",
    "    sample = []\n",
    "    for i in range(dataset_size):\n",
    "        l = random.randint(min_value, max_value)\n",
    "        r = random.randint(min_value, max_value)\n",
    "        op = random.choice(allowed_operator)\n",
    "        if op == \"-\":\n",
    "            sulotion = l - r\n",
    "        if op == '+':\n",
    "            sulotion = l + r \n",
    "        sample.append((str(l)+op+str(r), str(sulotion)))\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "equations = generate_equations([\"+\", \"-\"], 3, 0, 9999)\n",
    "equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "allowed_operator = [\"+\", \"-\"]\n",
    "dataset_size = 100000\n",
    "data = generate_equations(allowed_operator, dataset_size, 0, 9999)\n",
    "train_set, test_set = train_test_split(data, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "print(train_set[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for network \n",
    "The next stage is to creating mappings of the characters to their indices in some vocabulary. The dictionary is fixed(0-9, +, -), so it is easy to encode the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {word:idx for (idx, word) in enumerate(\"^$#+-1234567890\")}\n",
    "id2word = {idx:word for (idx, word) in enumerate(\"^$#+-1234567890\")}\n",
    "print(word2id)\n",
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special symbols\n",
    "start_symbol = '^'   #0, beginning of the decoding\n",
    "end_symbol = \"$\"     #1, end of the string, both for input and output\n",
    "padding_symbol = '#' #2, padding symbol, to make the input placeholds' length consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "Convert a sentence to a list of vocabulary word.\n",
    "* Predifined length padding_len\n",
    "* Padding with \"#\"\n",
    "* Ends with \"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_ids(sentence, word2id, padded_len):\n",
    "    sent_ids = [word2id[i] for i in sentence]\n",
    "    if (len(sent_ids) >= padded_len):\n",
    "        sent_ids = sent_ids[:padded_len]\n",
    "        sent_ids[-1] = 1\n",
    "    else:\n",
    "        sent_ids.append(1)\n",
    "        while(len(sent_ids) < padded_len):\n",
    "            sent_ids.append(2)\n",
    "    sent_len = min(len(sentence)+1, padded_len)\n",
    "    return sent_ids, sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"123+123\"\n",
    "print(sentence_to_ids(sentence, word2id, 7),\"\\n\",\n",
    "      sentence_to_ids(sentence, word2id, 8),\"\\n\",\n",
    "      sentence_to_ids(sentence, word2id, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert back\n",
    "def ids_to_sentence(ids, id2word):\n",
    "    return [id2word[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ids_to_sentence([5,6,7,3,5,6,1], id2word))\n",
    "print(ids_to_sentence([5, 6, 7, 3, 5, 6, 7, 1], id2word))\n",
    "print(ids_to_sentence([5, 6, 7, 3, 5, 6, 7, 1, 2, 2], id2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network building\n",
    "### Generate batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_ids(sentences, word2id, max_len):\n",
    "    max_len_in_batch = min(max(len(s) for s in sentences)+1, max_len)\n",
    "    batch_ids, batch_ids_len = [], []\n",
    "    for sentence in sentences:\n",
    "        ids, ids_len = sentence_to_ids(sentence, word2id, max_len_in_batch)\n",
    "        batch_ids.append(ids)\n",
    "        batch_ids_len.append(ids_len)\n",
    "    return batch_ids, batch_ids_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(samples, batch_size = 64):\n",
    "    X, Y = [], []\n",
    "    for i, (x,y) in enumerate(samples, 1):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        if i%batch_size == 0:\n",
    "            yield X, Y\n",
    "            X, Y = [], []\n",
    "    if X and Y:\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =  train_set[0]\n",
    "print(sentences)\n",
    "ids, sent_lens = batch_to_ids(sentences, word2id, max_len = 100)\n",
    "print(ids, sent_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_placeholders(self):\n",
    "    self.input_batch = tf.placeholder(shape = (None, None), dtype=tf.int32, name = \"input_batch\")\n",
    "    self.input_batch_lengths = tf.placeholder(shape = (None,), dtype=tf.int32, name = \"input_batch_lengths\")\n",
    "    \n",
    "    self.ground_truth = tf.placeholder(shape = (None, None), dtype=tf.int32)\n",
    "    self.ground_truth_lengths = tf.placeholder(shape = (None, ), dtype = tf.int32)\n",
    "    \n",
    "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape = [])\n",
    "    self.learning_rate_ph = tf.placeholder(dtype=tf.float32, shape = [])\n",
    "Seq2SeqModel.__declare_placeholders = classmethod(declare_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the layer(Embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform as a dictionary to encode the input batch()\n",
    "def create_embeddings(self, vocab_size, embeddings_size):\n",
    "    random_initializer = tf.random_uniform((vocab_size, embeddings_size), -1.0, 1.0)\n",
    "    self.embeddings = tf.Variable(random_initializer)\n",
    "    \n",
    "    self.input_batch_embedded = tf.nn.embedding_lookup(self.embeddings, self.input_batch)\n",
    "Seq2SeqModel.__create_embeddings = classmethod(create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Encoding an input sequence to a real-valued vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(self, hidden_size):\n",
    "    encoder_cell = tf.nn.run_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(hidden_size),\n",
    "                                                input_keep_prob = self.dropout_ph,\n",
    "                                                output_keep_prob = self.dropout_ph)\n",
    "    \n",
    "    _, self.final_encoder_state = tf.nn.dynamic_rnn(encoder_cell, \n",
    "                                                   self.input_batch_embedded,\n",
    "                                                   dtype = tf.float32,\n",
    "                                                   sequence_length = self.input_batch_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.__build_encoder = classmethod(build_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(self, hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id):\n",
    "    batch_size = tf.shape(self.input_bacth)[0];\n",
    "    start_tokens = tf.fill([batch_size], start_symbol_id)\n",
    "    ground_truth_as_input = tf.concat([tf.expand_dims(start_tokens, 1), self.ground_truth],1)\n",
    "    \n",
    "    self.ground_truth_embedded = tf.nn.embedding_lookup(self.embeddings, ground_truth_as_input)\n",
    "    \n",
    "    train_helper = tf.contrib.seq2seq.TrainingHelper(self.ground_truth_embedded,\n",
    "                                                    self.ground_truth_lengths)\n",
    "    \n",
    "    infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(self.embeddings, start_tokens, end_symbol_id)\n",
    "    \n",
    "    def decode(helper, scope, reuse = None):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            decoder_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.GRUCell(hidden_size, reuse),\n",
    "                                                        input_keep_prob = self.dropout_ph,\n",
    "                                                         output_keep_prob = self.dropout_ph)\n",
    "            decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(deocder_cell, vocab_size, reuse = reuse)\n",
    "\n",
    "            deocder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, self.final_encoder_state)\n",
    "            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder, maximum_iterations=max_iter,\n",
    "                                                             output_time_major = False, impute_finished = True)\n",
    "            return outputs\n",
    "    self.train_outputs = decode(train_helper, 'decode')\n",
    "    self.infer_outputs = decode(infer_helper, 'decode', reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.__build_encoder = classmethod(build_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(self):\n",
    "    weights = tf.cast(tf.sequence_mask(self.ground_truth_lengths), dtype=tf.float32)\n",
    "    self.loss = tf.contrib.seq2seq.sequence_loss(self.train_outputs.rnn_output, self.ground_truth, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.__compute_loss = classmethod(compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_optimization(self):\n",
    "    self.train_op = tf.contrib.layers.optimize_loss(self.loss, tf.train.get_global_step(),\n",
    "                                                   self.learning_rate_ph, 'Adam', clip_gradients = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.__perform_optimization = classmethod(perform_optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(self, vocab_size, embeddings_size, hidden_size, \n",
    "               max_iter, start_symbol_id, end_symbol_id, padding_symbol_id):\n",
    "    \n",
    "    self.__declare_placeholders()\n",
    "    self.__create_embeddings(vocab_size, embeddings_size)\n",
    "    self.__build_encoder(hidden_size)\n",
    "    self.__build_decoder(hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id)\n",
    "    \n",
    "    self.__compute_loss()\n",
    "    self.__perform_optimization()\n",
    "    \n",
    "    self.train_predictions = self.train_outputs.sample_id\n",
    "    self.infer_predictions = self.infer_outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.__init__ = classmethod(init_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(self, session, X, X_seq_len, Y, Y_seq_len, learning_rate, dropout_keep_probability):\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len,\n",
    "            self.ground_truth: Y,\n",
    "            self.ground_truth_lengths: Y_seq_len,\n",
    "            self.learning_rate_ph: learning_rate,\n",
    "            self.dropout_ph: dropout_keep_probability\n",
    "        }\n",
    "    pred, loss, _ = session.run([\n",
    "            self.train_predictions,\n",
    "            self.loss,\n",
    "            self.train_op], feed_dict=feed_dict)\n",
    "    return pred, loss\n",
    "Seq2SeqModel.train_on_batch = classmethod(train_on_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_batch(self, session, X, X_seq_len):\n",
    "    feed_dict = {\n",
    "        self.input_batch: X,\n",
    "        self.input_batch_lengths: X_seq_len,\n",
    "    }\n",
    "    ######### YOUR CODE HERE #############\n",
    "    pred = session.run([\n",
    "            self.infer_predictions\n",
    "        ], feed_dict=feed_dict)[0]\n",
    "    return pred\n",
    "\n",
    "def predict_for_batch_with_loss(self, session, X, X_seq_len, Y, Y_seq_len):\n",
    "    feed_dict = {\n",
    "        self.input_batch: X,\n",
    "        self.input_batch_lengths: X_seq_len,\n",
    "        self.ground_truth: Y,\n",
    "        self.ground_truth_lengths: Y_seq_len,\n",
    "    }\n",
    "    ######### YOUR CODE HERE #############\n",
    "    pred, loss = session.run([\n",
    "            self.infer_predictions,\n",
    "            self.loss,\n",
    "        ], feed_dict=feed_dict)\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2SeqModel.predict_for_batch = classmethod(predict_for_batch)\n",
    "Seq2SeqModel.predict_for_batch_with_loss = classmethod(predict_for_batch_with_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = Seq2SeqModel(len(word2id), 20, 512, 7,\n",
    "                     word2id[start_symbol], word2id[end_symbol], word2id[padding_symbol])\n",
    "\n",
    "batch_size = 128 \n",
    "n_epochs = 10 \n",
    "learning_rate = 0.001 \n",
    "dropout_keep_probability = 0.5 \n",
    "max_len = 20 \n",
    "\n",
    "n_step = int(len(train_set) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "            \n",
    "invalid_number_prediction_counts = []\n",
    "all_model_predictions = []\n",
    "all_ground_truth = []\n",
    "\n",
    "print('Start training... \\n')\n",
    "for epoch in range(n_epochs):  \n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    print('Train: epoch', epoch + 1)\n",
    "    for n_iter, (X_batch, Y_batch) in enumerate(generate_batches(train_set, batch_size=batch_size)):\n",
    "        ######################################\n",
    "        ######### YOUR CODE HERE #############\n",
    "        ######################################\n",
    "        # prepare the data (X_batch and Y_batch) for training\n",
    "        # using function batch_to_ids\n",
    "        X, X_seq_len = batch_to_ids(X_batch, word2id, max_len)\n",
    "        Y, Y_seq_len = batch_to_ids(Y_batch, word2id, max_len)\n",
    "        predictions, loss = model.train_on_batch(session,\n",
    "                                                 X,\n",
    "                                                 X_seq_len,\n",
    "                                                 Y,\n",
    "                                                 Y_seq_len,\n",
    "                                                 learning_rate,\n",
    "                                                 dropout_keep_probability) ######### YOUR CODE HERE #############\n",
    "        \n",
    "        if n_iter % 200 == 0:\n",
    "            print(\"Epoch: [%d/%d], step: [%d/%d], loss: %f\" % (epoch + 1, n_epochs, n_iter + 1, n_step, loss))\n",
    "                \n",
    "    X_sent, Y_sent = next(generate_batches(test_set, batch_size=batch_size))\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    # prepare test data (X_sent and Y_sent) for predicting \n",
    "    # quality and computing value of the loss function\n",
    "    # using function batch_to_ids\n",
    "    \n",
    "    X_test, X_test_len = batch_to_ids(X_sent, word2id, max_len)\n",
    "    Y_test, Y_test_len = batch_to_ids(Y_sent, word2id, max_len)\n",
    "    \n",
    "    predictions, loss = model.predict_for_batch_with_loss(session, X_test, X_test_len, Y_test, Y_test_len) ######### YOUR CODE HERE #############\n",
    "    print('Test: epoch', epoch + 1, 'loss:', loss,)\n",
    "    for x, y, p  in list(zip(X, Y, predictions))[:3]:\n",
    "        print('X:',''.join(ids_to_sentence(x, id2word)))\n",
    "        print('Y:',''.join(ids_to_sentence(y, id2word)))\n",
    "        print('O:',''.join(ids_to_sentence(p, id2word)))\n",
    "        print('')\n",
    "\n",
    "    model_predictions = []\n",
    "    ground_truth = []\n",
    "    invalid_number_prediction_count = 0\n",
    "    # For the whole test set calculate ground-truth values (as integer numbers)\n",
    "    # and prediction values (also as integers) to calculate metrics.\n",
    "    # If generated by model number is not correct (e.g. '1-1'), \n",
    "    # increase invalid_number_prediction_count and don't append this and corresponding\n",
    "    # ground-truth value to the arrays.\n",
    "    for X_batch, Y_batch in generate_batches(test_set, batch_size=batch_size):\n",
    "        ######################################\n",
    "        ######### YOUR CODE HERE #############\n",
    "        ######################################\n",
    "        X, X_seq_len = batch_to_ids(X_batch, word2id, max_len)\n",
    "        Y, Y_seq_len = batch_to_ids(Y_batch, word2id, max_len)\n",
    "        predictions = model.predict_for_batch(session, X, X_seq_len)\n",
    "        for y, p in zip(Y, predictions):\n",
    "            valid_y = ''.join(ids_to_sentence(y, id2word))\n",
    "            valid_y = valid_y[:valid_y.find('$')]\n",
    "            valid_p = ''.join(ids_to_sentence(p, id2word))\n",
    "            valid_p = valid_p if -1 == valid_p.find('$') else valid_p[:valid_p.find('$')]\n",
    "            try:\n",
    "                po = int(valid_p)\n",
    "                py = int(valid_y)\n",
    "                model_predictions.append(po)\n",
    "                ground_truth.append(py)\n",
    "            except:\n",
    "                print(valid_y, valid_p)\n",
    "                invalid_number_prediction_count += 1\n",
    "    \n",
    "    all_model_predictions.append(model_predictions)\n",
    "    all_ground_truth.append(ground_truth)\n",
    "    invalid_number_prediction_counts.append(invalid_number_prediction_count)\n",
    "            \n",
    "print('\\n...training finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "for i, (gts, predictions, invalid_number_prediction_count) in enumerate(zip(all_ground_truth,\n",
    "                                                                            all_model_predictions,\n",
    "                                                                            invalid_number_prediction_counts), 1):\n",
    "    mae = mean_absolute_error(gts, predictions) ######### YOUR CODE HERE #############\n",
    "    print(\"Epoch: %i, MAE: %f, Invalid numbers: %i\" % (i, mae, invalid_number_prediction_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
